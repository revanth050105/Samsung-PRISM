{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "System version: 3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)] <br>\n",
                "Tensorflow version: 2.6.1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install retrying\n",
                "!pip install yaml\n",
                "!pip install nbformat\n",
                "!pip install nbconvert\n",
                "!pip install --upgrade typing_extensions\n",
                "!pip install recommenders --no-deps"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "System version: 3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]\n",
                        "Tensorflow version: 2.6.1\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "import numpy as np\n",
                "import zipfile\n",
                "from tqdm import tqdm\n",
                "from tempfile import TemporaryDirectory\n",
                "import tensorflow as tf\n",
                "tf.get_logger().setLevel('ERROR')\n",
                "import recommenders\n",
                "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources \n",
                "from recommenders.models.newsrec.newsrec_utils import prepare_hparams\n",
                "from recommenders.models.newsrec.models.naml import NAMLModel\n",
                "from recommenders.models.newsrec.io.mind_all_iterator import MINDAllIterator\n",
                "from recommenders.models.newsrec.newsrec_utils import get_mind_data_set\n",
                "from recommenders.utils.notebook_utils import store_metadata\n",
                "\n",
                "print(\"System version: {}\".format(sys.version))\n",
                "print(\"Tensorflow version: {}\".format(tf.__version__))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prepare Parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "epochs = 5\n",
                "seed = 42\n",
                "batch_size = 32\n",
                "\n",
                "# demo, small, large\n",
                "MIND_type = 'demo'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Download and load data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 17.0k/17.0k [00:25<00:00, 669KB/s]\n",
                        "100%|██████████| 9.84k/9.84k [00:14<00:00, 675KB/s]\n",
                        "100%|██████████| 95.0k/95.0k [02:20<00:00, 674KB/s]\n"
                    ]
                }
            ],
            "source": [
                "model_path = \"...\"   # path to save the model weights\n",
                "data_path = \"...\"    # path to the data\n",
                "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
                "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
                "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
                "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
                "wordEmb_file = os.path.join(data_path, \"utils\", \"embedding_all.npy\")\n",
                "userDict_file = os.path.join(data_path, \"utils\", \"uid2index.pkl\")\n",
                "wordDict_file = os.path.join(data_path, \"utils\", \"word_dict_all.pkl\")\n",
                "vertDict_file = os.path.join(data_path, \"utils\", \"vert_dict.pkl\")\n",
                "subvertDict_file = os.path.join(data_path, \"utils\", \"subvert_dict.pkl\")\n",
                "yaml_file = os.path.join(data_path, \"utils\", r'naml.yaml')\n",
                "\n",
                "mind_url, mind_train_dataset, mind_dev_dataset, mind_utils = get_mind_data_set(MIND_type)\n",
                "\n",
                "if not os.path.exists(train_news_file):\n",
                "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
                "    \n",
                "if not os.path.exists(valid_news_file):\n",
                "    download_deeprec_resources(mind_url, \\\n",
                "                               os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
                "if not os.path.exists(yaml_file):\n",
                "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/newsrec/', \\\n",
                "                               os.path.join(data_path, 'utils'), mind_utils)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "print(os.getcwd())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create hyper-parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "hparams = prepare_hparams(yaml_file, \n",
                "                          vert_num=max(vert_dict.values()) + 1,  \n",
                "                          subvert_num=max(subvert_dict.values()) + 1,\n",
                "                          batch_size=32,\n",
                "                          epochs=5,\n",
                "                          wordEmb_file=wordEmb_file,\n",
                "                          wordDict_file=wordDict_file, \n",
                "                          userDict_file=userDict_file,\n",
                "                          vertDict_file=vertDict_file, \n",
                "                          subvertDict_file=subvertDict_file,\n",
                "                          )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "iterator = MINDAllIterator"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train the NAML model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = NAMLModel(hparams, iterator, seed=seed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "\n",
                "with open(vertDict_file, \"rb\") as f:\n",
                "    vert_dict = pickle.load(f)\n",
                "\n",
                "with open(subvertDict_file, \"rb\") as f:\n",
                "    subvert_dict = pickle.load(f)\n",
                "\n",
                "print(\"Max index in vert_dict:\", max(vert_dict.values()))\n",
                "print(\"Max index in subvert_dict:\", max(subvert_dict.values()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "1085it [1:02:26,  3.45s/it]\n",
                        "0it [00:00, ?it/s]d:\\College D drive\\Samsungggg PRISM\\NAML\\naml_env\\lib\\site-packages\\keras\\engine\\training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
                        "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
                        "18693it [00:52, 357.37it/s]\n",
                        "7507it [03:49, 32.77it/s]\n",
                        "7538it [00:01, 7414.87it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "at epoch 1\n",
                        "train info: logloss loss:1.4898013003960182\n",
                        "eval info: group_auc:0.5863, mean_mrr:0.2587, ndcg@10:0.3485, ndcg@5:0.2841\n",
                        "at epoch 1 , train time: 3746.5 eval time: 288.4\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "1085it [1:02:51,  3.48s/it]\n",
                        "18693it [00:50, 367.32it/s]\n",
                        "7507it [03:24, 36.75it/s]\n",
                        "7538it [00:01, 6383.59it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "at epoch 2\n",
                        "train info: logloss loss:1.4130157224593625\n",
                        "eval info: group_auc:0.6247, mean_mrr:0.2901, ndcg@10:0.3824, ndcg@5:0.3226\n",
                        "at epoch 2 , train time: 3771.3 eval time: 263.3\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "1085it [1:03:03,  3.49s/it]\n",
                        "18693it [00:49, 376.76it/s]\n",
                        "7507it [03:21, 37.20it/s]\n",
                        "7538it [00:00, 7746.97it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "at epoch 3\n",
                        "train info: logloss loss:1.3693901009273968\n",
                        "eval info: group_auc:0.6357, mean_mrr:0.2824, ndcg@10:0.381, ndcg@5:0.3189\n",
                        "at epoch 3 , train time: 3783.7 eval time: 258.3\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "1085it [1:02:16,  3.44s/it]\n",
                        "18693it [00:49, 379.99it/s]\n",
                        "7507it [03:26, 36.39it/s]\n",
                        "7538it [00:00, 7753.16it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "at epoch 4\n",
                        "train info: logloss loss:1.3387556996763028\n",
                        "eval info: group_auc:0.6451, mean_mrr:0.2995, ndcg@10:0.3948, ndcg@5:0.3343\n",
                        "at epoch 4 , train time: 3736.3 eval time: 262.4\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "1085it [1:03:27,  3.51s/it]\n",
                        "18693it [00:49, 376.05it/s]\n",
                        "7507it [03:25, 36.46it/s]\n",
                        "7538it [00:00, 7751.65it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "at epoch 5\n",
                        "train info: logloss loss:1.320486850947279\n",
                        "eval info: group_auc:0.6448, mean_mrr:0.2976, ndcg@10:0.3912, ndcg@5:0.326\n",
                        "at epoch 5 , train time: 3807.8 eval time: 262.4\n",
                        "Wall time: 5h 36min 20s\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<recommenders.models.newsrec.models.naml.NAMLModel at 0x298ae1aac88>"
                        ]
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "model.fit(train_news_file, train_behaviors_file, valid_news_file, valid_behaviors_file)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "18693it [00:46, 398.83it/s]\n",
                        "7507it [03:24, 36.79it/s]\n",
                        "7538it [00:00, 7800.13it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'group_auc': 0.6448, 'mean_mrr': 0.2976, 'ndcg@5': 0.326, 'ndcg@10': 0.3912}\n",
                        "Wall time: 4min 17s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "res_syn = model.run_eval(valid_news_file, valid_behaviors_file)\n",
                "print(res_syn)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/notebook_utils.json+json": {
                            "data": 0.6448,
                            "encoder": "json",
                            "name": "group_auc"
                        }
                    },
                    "metadata": {
                        "notebook_utils": {
                            "data": true,
                            "display": false,
                            "name": "group_auc"
                        }
                    },
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/notebook_utils.json+json": {
                            "data": 0.2976,
                            "encoder": "json",
                            "name": "mean_mrr"
                        }
                    },
                    "metadata": {
                        "notebook_utils": {
                            "data": true,
                            "display": false,
                            "name": "mean_mrr"
                        }
                    },
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/notebook_utils.json+json": {
                            "data": 0.326,
                            "encoder": "json",
                            "name": "ndcg@5"
                        }
                    },
                    "metadata": {
                        "notebook_utils": {
                            "data": true,
                            "display": false,
                            "name": "ndcg@5"
                        }
                    },
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/notebook_utils.json+json": {
                            "data": 0.3912,
                            "encoder": "json",
                            "name": "ndcg@10"
                        }
                    },
                    "metadata": {
                        "notebook_utils": {
                            "data": true,
                            "display": false,
                            "name": "ndcg@10"
                        }
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "store_metadata(\"group_auc\", res_syn['group_auc'])\n",
                "store_metadata(\"mean_mrr\", res_syn['mean_mrr'])\n",
                "store_metadata(\"ndcg@5\", res_syn['ndcg@5'])\n",
                "store_metadata(\"ndcg@10\", res_syn['ndcg@10'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs(model_path, exist_ok=True)\n",
                "model.model.save_weights(os.path.join(model_path, \"naml_ckpt\"))"
            ]
        }
    ],
    "metadata": {
        "celltoolbar": "Tags",
        "kernelspec": {
            "display_name": "naml_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
