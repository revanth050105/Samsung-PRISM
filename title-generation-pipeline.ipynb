{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T18:42:26.652660Z",
     "iopub.status.busy": "2025-02-10T18:42:26.652157Z",
     "iopub.status.idle": "2025-02-10T18:42:45.689621Z",
     "shell.execute_reply": "2025-02-10T18:42:45.688169Z",
     "shell.execute_reply.started": "2025-02-10T18:42:26.652618Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\n",
      "jupyterlab 4.3.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "plotnine 0.14.3 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\n",
      "tensorflow 2.16.1 requires ml-dtypes~=0.3.1, but you have ml-dtypes 0.5.0 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "ydata-profiling 4.12.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain groq langchain_groq langchain_community --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "\n",
    "trainfilename = \"/kaggle/input/mind-demo/MIND Demo Dataset/train/behaviors.tsv\"\n",
    "newsfilename = \"/kaggle/input/mind-demo/MIND Demo Dataset/train/news.tsv\"\n",
    "output_csv_path = \"/kaggle/working/generated_headlines.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"deepseek-r1-distill-llama-70b\"\n",
    "os.environ[\"GROQ_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_USERS = 50\n",
    "NUM_ARTICLES = 10\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize(sent):\n",
    "    pat = re.compile(r'[\\w]+|[.,!?;|]')\n",
    "    return pat.findall(sent.lower()) if isinstance(sent, str) else []\n",
    "\n",
    "def read_news(filename):\n",
    "    \"\"\"Reads the MIND news.tsv file and processes news articles.\"\"\"\n",
    "    news = {}\n",
    "    news_data = pd.read_csv(filename, sep='\\t', header=None, names=[\n",
    "        \"news_id\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"entity_title\", \"entity_abstract\"\n",
    "    ])\n",
    "    news_data.fillna(value=\" \", inplace=True)\n",
    "    \n",
    "    for _, row in news_data.iterrows():\n",
    "        doc_id = row[\"news_id\"]\n",
    "        title_tokens = word_tokenize(row[\"title\"])\n",
    "        abstract_tokens = word_tokenize(row[\"abstract\"])\n",
    "        news[doc_id] = {\n",
    "            \"title\": title_tokens,\n",
    "            \"abstract\": abstract_tokens\n",
    "        }\n",
    "    return news\n",
    "\n",
    "def read_user_interactions(filename):\n",
    "    \"\"\"Reads the MIND behaviors.tsv file and extracts user interactions.\"\"\"\n",
    "    user_interactions = {}\n",
    "    data = pd.read_csv(filename, sep='\\t', header=None, names=[\n",
    "        \"impression_id\", \"user_id\", \"timestamp\", \"history\", \"impressions\"\n",
    "    ])\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        user_id = row[\"user_id\"]\n",
    "        clicked_news = row[\"history\"].split() if isinstance(row[\"history\"], str) else []\n",
    "        impressions = row[\"impressions\"].split() if isinstance(row[\"impressions\"], str) else []\n",
    "\n",
    "        if user_id not in user_interactions:\n",
    "            user_interactions[user_id] = {\"positive\": set(), \"negative\": set()}\n",
    "\n",
    "        user_interactions[user_id][\"positive\"].update(clicked_news)\n",
    "        \n",
    "        for item in impressions:\n",
    "            parts = item.split('-')\n",
    "            if len(parts) == 2 and parts[1] == '0':  # Click label 0 = not clicked\n",
    "                user_interactions[user_id][\"negative\"].add(parts[0])\n",
    "    \n",
    "    return user_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading and processing MIND dataset...\")\n",
    "news = read_news(newsfilename)\n",
    "user_interactions = read_user_interactions(trainfilename)\n",
    "\n",
    "# filtered_users = {user: data for user, data in user_interactions.items() if len(data[\"positive\"]) > 25}\n",
    "filtered_users = {user: data for user, data in user_interactions.items() if 10 < len(data[\"positive\"]) < 20}\n",
    "filtered_users_list = [{\"user_id\": user, **data} for user, data in filtered_users.items()]\n",
    "\n",
    "print(f\"Total users: {len(user_interactions)}\")\n",
    "print(f\"Users with <20 and >10 positive articles: {len(filtered_users_list)}\")\n",
    "\n",
    "selected_users = random.sample(filtered_users_list, min(NUM_USERS, len(filtered_users_list)))\n",
    "selected_articles = random.sample(list(news.keys()), NUM_ARTICLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=MODEL_ID,\n",
    "    temperature=0.7,\n",
    "    max_retries=2,\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Variation:\n",
    "\"\"\"\n",
    "You are a professional news headline rewriter specializing in personalized content. Your task is to create a new, engaging headline for a news article that is tailored to a specific user's interests. It is critical that your headline uses simple, common language because our recommendation system relies on a fixed word dictionary; any rare or unknown words will be mapped to a default token (0), which can negatively impact the predicted click probability.\n",
    "\n",
    "You are provided with the following information:\n",
    "\n",
    "1. User's Positive Context:\n",
    "   - A collection of headlines from news articles that the user has liked.\n",
    "   - These headlines reflect the topics, style, and tone that resonate with the user.\n",
    "   - **Important:** Directly incorporate the exact key words from these headlines into your new headline. Do not replace these words with synonyms; the exact wording is important.\n",
    "\n",
    "2. User's Negative Context:\n",
    "   - A collection of headlines from news articles that the user did not like.\n",
    "   - Avoid using any language, tone, or topics similar to these headlines.\n",
    "\n",
    "3. Target Article Information:\n",
    "   - The original headline and the body of the target news article, which convey its main content and tone.\n",
    "\n",
    "Instructions:\n",
    "- Generate a completely new, personalized headline for the target article.\n",
    "- Use the exact key words from the positive context as inspirationâ€”do not modify them or use synonyms. Their precise form is essential.\n",
    "- Do not include any phrasing or elements that appear in the negative context.\n",
    "- Reflect the primary content and tone of the target article.\n",
    "- Do not provide any explanation or commentary; output only the final rewritten headline.\n",
    "- Ensure the headline is creative, distinctive, and clearly targeted to this specific user.\n",
    "\n",
    "User's Positive Context:\n",
    "{positive_context}\n",
    "\n",
    "User's Negative Context:\n",
    "{negative_context}\n",
    "\n",
    "Target Article Headline:\n",
    "{target_headline}\n",
    "\n",
    "Target Article Body:\n",
    "{target_body}\n",
    "\n",
    "Rewritten Personalized Headline:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T18:50:56.050677Z",
     "iopub.status.busy": "2025-02-10T18:50:56.050218Z",
     "iopub.status.idle": "2025-02-10T19:42:16.619491Z",
     "shell.execute_reply": "2025-02-10T19:42:16.617101Z",
     "shell.execute_reply.started": "2025-02-10T18:50:56.050636Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def truncate_context(context, max_tokens=750):\n",
    "    tokens = context.split()\n",
    "    return \" \".join(tokens[:max_tokens]) if len(tokens) > max_tokens else context\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a professional news headline rewriter with a deep understanding of user interests. Your task is to generate a new, personalized, and engaging headline for a news article.\n",
    "\n",
    "You are provided with:\n",
    "1. The user's positive news context: these are headlines of articles the user liked. Analyze the style, topics, and tone that the user prefers.\n",
    "2. The user's negative news context: these are headlines of articles the user did not like. Avoid the language, tone, or topics present in these headlines.\n",
    "3. The current headline and body of the target news article.\n",
    "\n",
    "Instructions:\n",
    "- Use the user's positive context as inspiration for style, tone, or topics, and ensure the headline feels uniquely tailored.\n",
    "- Use KEYWORDS from the positive context that the user will be interested in.\n",
    "- Steer clear of any phrasing or sentiment that appears in the negative context.\n",
    "- Reflect the main points and tone of the target article, while injecting personalized elements.\n",
    "- Do not provide any explanation or additional commentary; only output the final rewritten headline.\n",
    "- Ensure the headline is creative, distinctive, and clearly differentiated for each user.\n",
    "- The headline should be very specifically targeted to this user.\n",
    "\n",
    "User's Positive News Context:\n",
    "{positive_context}\n",
    "\n",
    "User's Negative News Context:\n",
    "{negative_context}\n",
    "\n",
    "Target Article Headline:\n",
    "{target_headline}\n",
    "\n",
    "Target Article Body:\n",
    "{target_body}\n",
    "\n",
    "Generate a rewritten headline:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"positive_context\", \"negative_context\", \"target_headline\", \"target_body\"],\n",
    "    template=prompt_template.strip()\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"\\nGenerating personalized headlines for users and articles...\\n\")\n",
    "for i in tqdm(range(0, len(selected_users), BATCH_SIZE), desc=\"User Batches\"):\n",
    "    batch_users = selected_users[i:i + BATCH_SIZE]\n",
    "    \n",
    "    for article_id in tqdm(selected_articles, desc=\"Articles\", leave=False):\n",
    "        if article_id not in news:\n",
    "            continue\n",
    "        \n",
    "        article = news[article_id]\n",
    "        target_headline = \" \".join(article[\"title\"])\n",
    "        target_body = \" \".join(article[\"abstract\"])\n",
    "        \n",
    "        for user_context in batch_users:\n",
    "            positive_context = \" | \".join([\" \".join(news[doc][\"title\"]) for doc in user_context[\"positive\"] if doc in news])\n",
    "            if not positive_context:\n",
    "                positive_context = \"No positive news history available.\"\n",
    "            else:\n",
    "                positive_context = truncate_context(positive_context, max_tokens=1000)\n",
    "            \n",
    "                negative_context = \" | \".join([\" \".join(news[doc][\"title\"]) for doc in list(user_context[\"negative\"])[:5] if doc in news])\n",
    "                if not negative_context:\n",
    "                    negative_context = \"No negative news history available.\"\n",
    "\n",
    "            \n",
    "            prompt_params = {\n",
    "                \"positive_context\": positive_context,\n",
    "                \"negative_context\": negative_context,\n",
    "                \"target_headline\": target_headline,\n",
    "                \"target_body\": target_body\n",
    "            }\n",
    "            \n",
    "            generated = llm_chain.run(prompt_params).strip()\n",
    "            cleaned_generated = re.sub(r'<think>.*?</think>', '', generated, flags=re.DOTALL).strip()\n",
    "            results.append({\n",
    "                \"user_id\": user_context[\"user_id\"],\n",
    "                \"article_id\": article_id,\n",
    "                \"original_headline\": target_headline,\n",
    "                \"generated_headline\": generated,\n",
    "                \"cleaned_headline\": cleaned_generated,\n",
    "                \"positive_context\": positive_context,\n",
    "                \"negative_context\": negative_context\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(output_csv_path, index=False)\n",
    "print(f\"\\nFinal results saved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1049650,
     "sourceId": 2565112,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6619999,
     "sourceId": 10685239,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
